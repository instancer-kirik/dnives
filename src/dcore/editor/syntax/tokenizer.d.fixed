module dcore.editor.syntax.tokenizer;

import std.regex;
import std.string;
import std.array;
import std.uni;
import std.conv;
import std.algorithm;
import std.stdio;

enum TokenType {
    text,
    keyword,
    identifier,
    operator,
    string,
    number,
    comment
}

/**
 * Token - Represents a syntax token
 */
struct Token {
    int position;          // Character position in line
    int length;            // Token length in characters
    string type;           // Token type (keyword, string, etc.)
    int lineIndex;         // Line index in document
    string text;           // Token text
    
    /**
     * Constructor
     */
    this(int position, int length, string type, int lineIndex, string text) {
        this.position = position;
        this.length = length;
        this.type = type;
        this.lineIndex = lineIndex;
        this.text = text;
    }
}

/**
 * Tokenizer - Base class for syntax tokenizers
 */
class Tokenizer {
    protected {
        string[] keywords;        // Language keywords
        Regex!string rxKeyword;   // Keyword regex
        Regex!string rxString;    // String regex
        Regex!string rxNumber;    // Number regex
        Regex!string rxComment;   // Comment regex
        Regex!string rxIdentifier;// Identifier regex
        Regex!string rxOperator;  // Operator regex
    }
    
    /**
     * Constructor
     */
    this() {
        // Default constructor
    }
    
    /**
     * Get name of tokenizer
     */
    string getName() {
        return "Generic";
    }
    
    /**
     * Get tokenizer description
     */
    string getDescription() {
        return "Generic tokenizer";
    }
    
    /**
     * Get supported file extensions
     */
    string[] getFileExtensions() {
        return [];
    }
    
    /**
     * Get supported languages
     */
    string[] getLanguages() {
        return [];
    }
    
    /**
     * Tokenize text into syntax tokens
     */
    Token[][] tokenize(dstring[] lines) {
        Token[][] result;
        
        // Tokenize each line
        for (int i = 0; i < lines.length; i++) {
            result ~= tokenizeLine(lines[i], i);
        }
        
        // Process multi-line tokens if needed
        processMultiLineTokens(result, lines);
        
        return result;
    }
    
    /**
     * Check if this tokenizer supports the given file
     */
    bool supportsFile(string filename) {
        import std.path : extension;
        string ext = extension(filename);
        if (ext.length > 0 && ext[0] == '.')
            ext = ext[1..$];
            
        return getFileExtensions().canFind(ext);
    }
    
    /// Tokenize a single line
    Token[] tokenizeLine(dstring text, int lineIndex) {
        Token[] tokens;
        string strText = text.toUTF8();
        
        // Find all tokens in the line
        int pos = 0;
        while (pos < strText.length) {
            // Skip whitespace
            if (isWhite(strText[pos])) {
                pos++;
                continue;
            }
            
            bool foundMatch = false;
            
            // Try to match a comment
            auto commentMatch = matchFirst(strText[pos..$], rxComment);
            if (!commentMatch.empty) {
                tokens ~= Token(pos, cast(int)commentMatch.hit.length, "comment", lineIndex, commentMatch.hit);
                pos += cast(int)commentMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // Try to match a string
            auto stringMatch = matchFirst(strText[pos..$], rxString);
            if (!stringMatch.empty) {
                tokens ~= Token(pos, cast(int)stringMatch.hit.length, "string", lineIndex, stringMatch.hit);
                pos += cast(int)stringMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // Try to match a number
            auto numberMatch = matchFirst(strText[pos..$], rxNumber);
            if (!numberMatch.empty) {
                tokens ~= Token(pos, cast(int)numberMatch.hit.length, "number", lineIndex, numberMatch.hit);
                pos += cast(int)numberMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // Try to match a keyword
            auto keywordMatch = matchFirst(strText[pos..$], rxKeyword);
            if (!keywordMatch.empty) {
                tokens ~= Token(pos, cast(int)keywordMatch.hit.length, "keyword", lineIndex, keywordMatch.hit);
                pos += cast(int)keywordMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // Try to match an identifier
            auto identifierMatch = matchFirst(strText[pos..$], rxIdentifier);
            if (!identifierMatch.empty) {
                tokens ~= Token(pos, cast(int)identifierMatch.hit.length, "identifier", lineIndex, identifierMatch.hit);
                pos += cast(int)identifierMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // Try to match an operator
            auto operatorMatch = matchFirst(strText[pos..$], rxOperator);
            if (!operatorMatch.empty) {
                tokens ~= Token(pos, cast(int)operatorMatch.hit.length, "operator", lineIndex, operatorMatch.hit);
                pos += cast(int)operatorMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // If no match found, treat as plain text
            if (!foundMatch) {
                tokens ~= Token(pos, 1, "text", lineIndex, [strText[pos]].idup);
                pos++;
            }
        }
        
        return tokens;
    }
    
    /// Process multiline tokens
    void processMultiLineTokens(Token[][] tokens, dstring[] lines) {
        // The generic tokenizer doesn't handle multi-line tokens
        // More advanced tokenizers would implement this
    }
}

/**
 * JavaScriptTokenizer - Tokenizer for JavaScript syntax
 */
class JavaScriptTokenizer : Tokenizer {
    /**
     * Constructor
     */
    this() {
        super();
        
        // Set JavaScript keywords
        keywords = [
            "break", "case", "catch", "class", "const", "continue", "debugger",
            "default", "delete", "do", "else", "export", "extends", "false",
            "finally", "for", "function", "if", "import", "in", "instanceof",
            "new", "null", "return", "super", "switch", "this", "throw", "true",
            "try", "typeof", "var", "void", "while", "with", "let", "yield",
            "async", "await", "static", "get", "set", "of", "from"
        ];
        
        // Initialize regexes
        initializeRegexes();
    }
    
    /**
     * Get name of tokenizer
     */
    override string getName() {
        return "JavaScript";
    }
    
    /**
     * Get tokenizer description
     */
    override string getDescription() {
        return "JavaScript syntax tokenizer";
    }
    
    /**
     * Get supported file extensions
     */
    override string[] getFileExtensions() {
        return ["js", "jsx", "mjs"];
    }
    
    /**
     * Get supported languages
     */
    override string[] getLanguages() {
        return ["javascript", "js"];
    }
    
    /**
     * Initialize regular expressions
     */
    private void initializeRegexes() {
        // Create keyword pattern from keywords list
        string keywordPattern = `\b(` ~ join(keywords, "|") ~ `)\b`;
        rxKeyword = regex(keywordPattern);
        
        // String patterns (including template literals)
        // Use string concatenation to avoid backtick issues
        rxString = regex(`"(?:[^"\\]|\\.)*"|'(?:[^'\\]|\\.)*'|` ~ "`" ~ `(?:[^` ~ "`" ~ `\\]|\\.)*` ~ "`");
        
        // Number pattern
        rxNumber = regex(`\b\d+(?:\.\d+)?(?:[eE][+-]?\d+)?\b|0x[0-9a-fA-F]+\b`);
        
        // Comment patterns
        rxComment = regex(`//.*$|/\*[\s\S]*?\*/`);
        
        // Identifier pattern
        rxIdentifier = regex(`\b[a-zA-Z_$][a-zA-Z0-9_$]*\b`);
        
        // Operator pattern
        rxOperator = regex(`[+\-*/%=&|^~<>!?:;,.\[\]{}()]|=>|===|!==|\+\+|--|&&|\|\|`);
    }
    
    /// Tokenize a single line
    override Token[] tokenizeLine(dstring text, int lineIndex) {
        Token[] tokens;
        string strText = text.toUTF8();
        
        // Find all tokens in the line
        int pos = 0;
        while (pos < strText.length) {
            // Skip whitespace
            if (isWhite(strText[pos])) {
                pos++;
                continue;
            }
            
            bool foundMatch = false;
            
            // Try to match a comment
            auto commentMatch = matchFirst(strText[pos..$], rxComment);
            if (!commentMatch.empty) {
                tokens ~= Token(pos, cast(int)commentMatch.hit.length, "comment", lineIndex, commentMatch.hit);
                pos += cast(int)commentMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // Try to match a string
            auto stringMatch = matchFirst(strText[pos..$], rxString);
            if (!stringMatch.empty) {
                tokens ~= Token(pos, cast(int)stringMatch.hit.length, "string", lineIndex, stringMatch.hit);
                pos += cast(int)stringMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // Try to match a number
            auto numberMatch = matchFirst(strText[pos..$], rxNumber);
            if (!numberMatch.empty) {
                tokens ~= Token(pos, cast(int)numberMatch.hit.length, "number", lineIndex, numberMatch.hit);
                pos += cast(int)numberMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // Try to match a keyword
            auto keywordMatch = matchFirst(strText[pos..$], rxKeyword);
            if (!keywordMatch.empty) {
                tokens ~= Token(pos, cast(int)keywordMatch.hit.length, "keyword", lineIndex, keywordMatch.hit);
                pos += cast(int)keywordMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // Try to match an identifier
            auto identifierMatch = matchFirst(strText[pos..$], rxIdentifier);
            if (!identifierMatch.empty) {
                tokens ~= Token(pos, cast(int)identifierMatch.hit.length, "identifier", lineIndex, identifierMatch.hit);
                pos += cast(int)identifierMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // Try to match an operator
            auto operatorMatch = matchFirst(strText[pos..$], rxOperator);
            if (!operatorMatch.empty) {
                tokens ~= Token(pos, cast(int)operatorMatch.hit.length, "operator", lineIndex, operatorMatch.hit);
                pos += cast(int)operatorMatch.hit.length;
                foundMatch = true;
                continue;
            }
            
            // If no match found, treat as plain text
            if (!foundMatch) {
                tokens ~= Token(pos, 1, "text", lineIndex, [strText[pos]].idup);
                pos++;
            }
        }
        
        return tokens;
    }
}

/**
 * CSSTokenizer - Tokenizer for CSS syntax
 */
class CSSTokenizer : Tokenizer {
    /**
     * Constructor
     */
    this() {
        super();
        
        // CSS doesn't have many keywords, but we include some common ones
        keywords = [
            "import", "charset", "namespace", "media", "keyframes", "from", "to",
            "important", "not", "only", "and", "or"
        ];
        
        // Initialize regexes
        initializeRegexes();
    }
    
    /**
     * Get name of tokenizer
     */
    override string getName() {
        return "CSS";
    }
    
    /**
     * Get tokenizer description
     */
    override string getDescription() {
        return "CSS syntax tokenizer";
    }
    
    /**
     * Get supported file extensions
     */
    override string[] getFileExtensions() {
        return ["css", "scss", "less"];
    }
    
    /**
     * Get supported languages
     */
    override string[] getLanguages() {
        return ["css", "scss", "less"];
    }
    
    /**
     * Initialize regular expressions
     */
    private void initializeRegexes() {
        // Create keyword pattern
        string keywordPattern = `\b(` ~ join(keywords, "|") ~ `)\b`;
        rxKeyword = regex(keywordPattern);
        
        // String pattern
        rxString = regex(`"(?:[^"\\]|\\.)*"|'(?:[^'\\]|\\.)*'`);
        
        // Number pattern (includes units)
        rxNumber = regex(`\b\d+(?:\.\d+)?(?:px|em|rem|%|vh|vw|vmin|vmax|s|ms|deg)?\b`);
        
        // Comment pattern
        rxComment = regex(`/\*[\s\S]*?\*/`);
        
        // Identifier pattern (includes selectors)
        rxIdentifier = regex(`[a-zA-Z_\-][a-zA-Z0-9_\-]*`);
        
        // Operator pattern
        rxOperator = regex(`[+>~:;,{}()#.\[\]=]`);
    }
}

/**
 * HTMLTokenizer - Tokenizer for HTML syntax
 */
class HTMLTokenizer : Tokenizer {
    /**
     * Constructor
     */
    this() {
        super();
        
        // HTML doesn't have traditional keywords, but we use these common tags/attributes
        keywords = [
            "html", "head", "body", "div", "span", "a", "img", "script", "style",
            "link", "meta", "title", "p", "h1", "h2", "h3", "h4", "h5", "h6",
            "ul", "ol", "li", "table", "tr", "td", "th", "form", "input", "button",
            "class", "id", "href", "src", "alt", "width", "height", "type"
        ];
        
        // Initialize regexes
        initializeRegexes();
    }
    
    /**
     * Get name of tokenizer
     */
    override string getName() {
        return "HTML";
    }
    
    /**
     * Get tokenizer description
     */
    override string getDescription() {
        return "HTML syntax tokenizer";
    }
    
    /**
     * Get supported file extensions
     */
    override string[] getFileExtensions() {
        return ["html", "htm", "xhtml", "xml"];
    }
    
    /**
     * Get supported languages
     */
    override string[] getLanguages() {
        return ["html", "xml"];
    }
    
    /**
     * Initialize regular expressions
     */
    private void initializeRegexes() {
        // Create keyword pattern
        string keywordPattern = `\b(` ~ join(keywords, "|") ~ `)\b`;
        rxKeyword = regex(keywordPattern);
        
        // String pattern
        rxString = regex(`"(?:[^"\\]|\\.)*"|'(?:[^'\\]|\\.)*'`);
        
        // Number pattern
        rxNumber = regex(`\b\d+(?:\.\d+)?(?:px|em|rem|%|vh|vw)?\b`);
        
        // Comment pattern
        rxComment = regex(`<!--[\s\S]*?-->`);
        
        // Identifier pattern
        rxIdentifier = regex(`[a-zA-Z_\-][a-zA-Z0-9_\-]*`);
        
        // Operator pattern (includes tag brackets)
        rxOperator = regex(`[<>=/!&]`);
    }
}

/**
 * TokenizerFactory - Factory for creating tokenizers
 */
class TokenizerFactory {
    private static Tokenizer[] _tokenizers;
    
    // Static constructor to register tokenizers
    static this() {
        // Register built-in tokenizers
        registerTokenizer(new JavaScriptTokenizer());
        registerTokenizer(new CSSTokenizer());
        registerTokenizer(new HTMLTokenizer());
        // More tokenizers can be added here
    }
    
    // Register a tokenizer
    static void registerTokenizer(Tokenizer tokenizer) {
        _tokenizers ~= tokenizer;
    }
    
    // Get tokenizer by file extension
    static Tokenizer getTokenizerForFile(string filename) {
        foreach (tokenizer; _tokenizers) {
            if (tokenizer.supportsFile(filename))
                return tokenizer;
        }
        
        // Return generic tokenizer if no specific one found
        return new Tokenizer();
    }
    
    // Get tokenizer by language name
    static Tokenizer getTokenizerForLanguage(string language) {
        foreach (tokenizer; _tokenizers) {
            if (tokenizer.getLanguages().canFind(language.toLower()))
                return tokenizer;
        }
        
        // Return generic tokenizer if no specific one found
        return new Tokenizer();
    }
    
    // Get all registered tokenizers
    static Tokenizer[] getAllTokenizers() {
        return _tokenizers.dup;
    }
}